{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYip-NDgpVRc"
      },
      "source": [
        "https://www.tensorflow.org/tutorials/load_data/text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKQo0eLfkDmV"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "QZXC_iB1kY7P"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import pathlib\n",
        "import csv\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "# import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZUSKoUerVmB",
        "outputId": "772cc6c8-4084-44b1-9bab-06070ff33e0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1905it [00:00, 8262.98it/s]\n"
          ]
        }
      ],
      "source": [
        "train_dir = \"./train/\"\n",
        "names, tests = [], []\n",
        "with open(\"coursedata.csv\", \"r\") as infile:\n",
        "    reader = csv.reader(infile)\n",
        "    for i, row in enumerate(tqdm(reader)):\n",
        "        names.append(row[0])\n",
        "        tests.append(row[3])\n",
        "        if not os.path.exists(train_dir+row[1]+\"/\"):\n",
        "            os.makedirs(train_dir+row[1]+\"/\")\n",
        "        with open(train_dir+row[1]+\"/\"+str(i)+\".txt\", \"w\") as outfile:\n",
        "          outfile.write(row[3].lower().strip()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCZSte2Hw3aY",
        "outputId": "aab2575a-6b2a-41c7-e795-e9b5e19bb980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1905 files belonging to 82 classes.\n",
            "Using 1524 files for training.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "raw_train_ds = utils.text_dataset_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9eUeU4KnwtZ",
        "outputId": "3d1ccf6e-de0a-43c7-f81b-b94e9b8acb95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label 0 corresponds to AAAS\n",
            "Label 1 corresponds to ACC\n",
            "Label 2 corresponds to AHST\n",
            "Label 3 corresponds to AME\n",
            "Label 4 corresponds to AMST\n",
            "Label 5 corresponds to ANTH\n",
            "Label 6 corresponds to ARBC\n",
            "Label 7 corresponds to ASLA\n",
            "Label 8 corresponds to ASTR\n",
            "Label 9 corresponds to ATHS\n",
            "Label 10 corresponds to BCSC\n",
            "Label 11 corresponds to BIOL\n",
            "Label 12 corresponds to BME\n",
            "Label 13 corresponds to BUS\n",
            "Label 14 corresponds to CASC\n",
            "Label 15 corresponds to CGRK\n",
            "Label 16 corresponds to CHE\n",
            "Label 17 corresponds to CHEM\n",
            "Label 18 corresponds to CHIN\n",
            "Label 19 corresponds to CIS\n",
            "Label 20 corresponds to CLST\n",
            "Label 21 corresponds to CLTR\n",
            "Label 22 corresponds to CSC\n",
            "Label 23 corresponds to CVSC\n",
            "Label 24 corresponds to DANC\n",
            "Label 25 corresponds to DMST\n",
            "Label 26 corresponds to DSCC\n",
            "Label 27 corresponds to EAS\n",
            "Label 28 corresponds to ECE\n",
            "Label 29 corresponds to ECON\n",
            "Label 30 corresponds to EESC\n",
            "Label 31 corresponds to EHUM\n",
            "Label 32 corresponds to ENGL\n",
            "Label 33 corresponds to ENT\n",
            "Label 34 corresponds to FIN\n",
            "Label 35 corresponds to FMST\n",
            "Label 36 corresponds to FREN\n",
            "Label 37 corresponds to GRMN\n",
            "Label 38 corresponds to GSWS\n",
            "Label 39 corresponds to HBRW\n",
            "Label 40 corresponds to HIST\n",
            "Label 41 corresponds to INTR\n",
            "Label 42 corresponds to ITAL\n",
            "Label 43 corresponds to JPNS\n",
            "Label 44 corresponds to JWST\n",
            "Label 45 corresponds to KORE\n",
            "Label 46 corresponds to LATN\n",
            "Label 47 corresponds to LAW\n",
            "Label 48 corresponds to LING\n",
            "Label 49 corresponds to LTST\n",
            "Label 50 corresponds to MATH\n",
            "Label 51 corresponds to ME\n",
            "Label 52 corresponds to MKT\n",
            "Label 53 corresponds to MSC\n",
            "Label 54 corresponds to MUSC\n",
            "Label 55 corresponds to NAVS\n",
            "Label 56 corresponds to NSCI\n",
            "Label 57 corresponds to OPT\n",
            "Label 58 corresponds to PHIL\n",
            "Label 59 corresponds to PHLT\n",
            "Label 60 corresponds to PHYS\n",
            "Label 61 corresponds to POLS\n",
            "Label 62 corresponds to PORT\n",
            "Label 63 corresponds to PSCI\n",
            "Label 64 corresponds to PSYC\n",
            "Label 65 corresponds to RELC\n",
            "Label 66 corresponds to RSST\n",
            "Label 67 corresponds to RUSS\n",
            "Label 68 corresponds to SABR\n",
            "Label 69 corresponds to SART\n",
            "Label 70 corresponds to SOCI\n",
            "Label 71 corresponds to SPAN\n",
            "Label 72 corresponds to STAT\n",
            "Label 73 corresponds to STR\n",
            "Label 74 corresponds to SUST\n",
            "Label 75 corresponds to TCS\n",
            "Label 76 corresponds to TEC\n",
            "Label 77 corresponds to TEE\n",
            "Label 78 corresponds to TEM\n",
            "Label 79 corresponds to TEO\n",
            "Label 80 corresponds to TME\n",
            "Label 81 corresponds to WRTG\n"
          ]
        }
      ],
      "source": [
        "for i, label in enumerate(raw_train_ds.class_names):\n",
        "  print(\"Label\", i, \"corresponds to\", label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3TLiHFon21Z",
        "outputId": "c6326c36-d792-44c5-c8a3-bc160fd4b423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1905 files belonging to 82 classes.\n",
            "Using 381 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# Create a validation set.\n",
        "raw_val_ds = utils.text_dataset_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "NcFpTQSvoBHY"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 10000\n",
        "\n",
        "binary_vectorize_layer = TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "7mcT1ptpoRsL"
      },
      "outputs": [],
      "source": [
        "MAX_SEQUENCE_LENGTH = 1024\n",
        "\n",
        "int_vectorize_layer = TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=MAX_SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "50fnQlJToVf4"
      },
      "outputs": [],
      "source": [
        "# Make a text-only dataset (without labels), then call `TextVectorization.adapt`.\n",
        "train_text = raw_train_ds.map(lambda text, labels: text)\n",
        "binary_vectorize_layer.adapt(train_text)\n",
        "int_vectorize_layer.adapt(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "lVCS9ZvOoaej"
      },
      "outputs": [],
      "source": [
        "def binary_vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return binary_vectorize_layer(text), label\n",
        "\n",
        "def int_vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return int_vectorize_layer(text), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XWZFzmSodo3",
        "outputId": "3b32dc9e-1d7a-47bf-bf81-4e66835427b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question tf.Tensor(b'in this course, students with prior yoga and/or dance experience will learn how to refine their skills through a continued exploration of asanas, pranayama, philosophy, and meditation. we will explore a more rigorous vinyasa flow practice, resulting in students developing more clarity regarding alignment, breath support, core aliveness, and, ultimately, body/self-awareness. while this is an individualized practice, the importance of community will be emphasized throughout as students share aspects of their practice with each other. readings, discussion, and reflective writing are inherent to deepening ones practice.', shape=(), dtype=string)\n",
            "Label tf.Tensor(24, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Retrieve a batch (of 32 reviews and labels) from the dataset.\n",
        "text_batch, label_batch = next(iter(raw_train_ds))\n",
        "first_question, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Question\", first_question)\n",
        "print(\"Label\", first_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZydqDzqtoi1b",
        "outputId": "2cb762a4-2349-4abe-ab73-bf7153d3cb6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'binary' vectorized question: tf.Tensor([[0. 1. 1. ... 0. 0. 0.]], shape=(1, 10000), dtype=float32)\n",
            "'int' vectorized question: tf.Tensor([[ 6 10  9 ...  0  0  0]], shape=(1, 1024), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "print(\"'binary' vectorized question:\",\n",
        "      binary_vectorize_text(first_question, first_label)[0])\n",
        "print(\"'int' vectorized question:\",\n",
        "      int_vectorize_text(first_question, first_label)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBXBzIbXo2R_",
        "outputId": "d8f9c546-ab01-4caf-9be4-de63e95096ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1289 --->  scheduled\n",
            "313 --->  sources\n",
            "Vocabulary size: 10000\n"
          ]
        }
      ],
      "source": [
        "print(\"1289 ---> \", int_vectorize_layer.get_vocabulary()[1289])\n",
        "print(\"313 ---> \", int_vectorize_layer.get_vocabulary()[313])\n",
        "print(\"Vocabulary size: {}\".format(len(int_vectorize_layer.get_vocabulary())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "aYmmvP5yo5ff"
      },
      "outputs": [],
      "source": [
        "binary_train_ds = raw_train_ds.map(binary_vectorize_text)\n",
        "binary_val_ds = raw_val_ds.map(binary_vectorize_text)\n",
        "\n",
        "int_train_ds = raw_train_ds.map(int_vectorize_text)\n",
        "int_val_ds = raw_val_ds.map(int_vectorize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3yH5LS52pBO4"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def configure_dataset(dataset):\n",
        "  return dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "8INnPPnOpDNX"
      },
      "outputs": [],
      "source": [
        "binary_train_ds = configure_dataset(binary_train_ds)\n",
        "binary_val_ds = configure_dataset(binary_val_ds)\n",
        "\n",
        "int_train_ds = configure_dataset(int_train_ds)\n",
        "int_val_ds = configure_dataset(int_val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfdavv3TpHCR",
        "outputId": "2af187a9-0195-480f-c7fb-a79342df9cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 3.9992 - accuracy: 0.2106 - val_loss: 3.6619 - val_accuracy: 0.2887\n",
            "Epoch 2/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 2.8379 - accuracy: 0.5761 - val_loss: 3.2100 - val_accuracy: 0.3990\n",
            "Epoch 3/40\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 2.1616 - accuracy: 0.6923 - val_loss: 2.9615 - val_accuracy: 0.4252\n",
            "Epoch 4/40\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 1.7546 - accuracy: 0.7238 - val_loss: 2.8294 - val_accuracy: 0.4383\n",
            "Epoch 5/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 1.5025 - accuracy: 0.7323 - val_loss: 2.7567 - val_accuracy: 0.4541\n",
            "Epoch 6/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 1.3338 - accuracy: 0.7388 - val_loss: 2.7149 - val_accuracy: 0.4541\n",
            "Epoch 7/40\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 1.2130 - accuracy: 0.7408 - val_loss: 2.6906 - val_accuracy: 0.4541\n",
            "Epoch 8/40\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 1.1220 - accuracy: 0.7395 - val_loss: 2.6771 - val_accuracy: 0.4593\n",
            "Epoch 9/40\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 1.0510 - accuracy: 0.7434 - val_loss: 2.6706 - val_accuracy: 0.4593\n",
            "Epoch 10/40\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.9939 - accuracy: 0.7448 - val_loss: 2.6686 - val_accuracy: 0.4567\n",
            "Epoch 11/40\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.9470 - accuracy: 0.7441 - val_loss: 2.6699 - val_accuracy: 0.4488\n",
            "Epoch 12/40\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.9076 - accuracy: 0.7434 - val_loss: 2.6736 - val_accuracy: 0.4462\n",
            "Epoch 13/40\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.8740 - accuracy: 0.7467 - val_loss: 2.6789 - val_accuracy: 0.4462\n",
            "Epoch 14/40\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.8449 - accuracy: 0.7507 - val_loss: 2.6854 - val_accuracy: 0.4436\n",
            "Epoch 15/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.8196 - accuracy: 0.7500 - val_loss: 2.6928 - val_accuracy: 0.4488\n",
            "Epoch 16/40\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.7971 - accuracy: 0.7500 - val_loss: 2.7008 - val_accuracy: 0.4488\n",
            "Epoch 17/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.7772 - accuracy: 0.7526 - val_loss: 2.7093 - val_accuracy: 0.4514\n",
            "Epoch 18/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.7593 - accuracy: 0.7546 - val_loss: 2.7181 - val_accuracy: 0.4541\n",
            "Epoch 19/40\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.7431 - accuracy: 0.7546 - val_loss: 2.7271 - val_accuracy: 0.4541\n",
            "Epoch 20/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.7284 - accuracy: 0.7533 - val_loss: 2.7364 - val_accuracy: 0.4541\n",
            "Epoch 21/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.7151 - accuracy: 0.7533 - val_loss: 2.7457 - val_accuracy: 0.4567\n",
            "Epoch 22/40\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.7028 - accuracy: 0.7533 - val_loss: 2.7551 - val_accuracy: 0.4567\n",
            "Epoch 23/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6916 - accuracy: 0.7526 - val_loss: 2.7645 - val_accuracy: 0.4567\n",
            "Epoch 24/40\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.6812 - accuracy: 0.7507 - val_loss: 2.7739 - val_accuracy: 0.4567\n",
            "Epoch 25/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.6716 - accuracy: 0.7513 - val_loss: 2.7833 - val_accuracy: 0.4567\n",
            "Epoch 26/40\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.6627 - accuracy: 0.7513 - val_loss: 2.7927 - val_accuracy: 0.4567\n",
            "Epoch 27/40\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.7513 - val_loss: 2.8020 - val_accuracy: 0.4567\n",
            "Epoch 28/40\n",
            "48/48 [==============================] - 0s 8ms/step - loss: 0.6468 - accuracy: 0.7520 - val_loss: 2.8114 - val_accuracy: 0.4541\n",
            "Epoch 29/40\n",
            "48/48 [==============================] - 0s 8ms/step - loss: 0.6396 - accuracy: 0.7520 - val_loss: 2.8206 - val_accuracy: 0.4541\n",
            "Epoch 30/40\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.6328 - accuracy: 0.7520 - val_loss: 2.8298 - val_accuracy: 0.4567\n",
            "Epoch 31/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.6265 - accuracy: 0.7520 - val_loss: 2.8389 - val_accuracy: 0.4541\n",
            "Epoch 32/40\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.6206 - accuracy: 0.7539 - val_loss: 2.8481 - val_accuracy: 0.4541\n",
            "Epoch 33/40\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6150 - accuracy: 0.7533 - val_loss: 2.8569 - val_accuracy: 0.4541\n",
            "Epoch 34/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.7539 - val_loss: 2.8663 - val_accuracy: 0.4514\n",
            "Epoch 35/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.7539 - val_loss: 2.8740 - val_accuracy: 0.4514\n",
            "Epoch 36/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.7539 - val_loss: 2.8854 - val_accuracy: 0.4514\n",
            "Epoch 37/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7539 - val_loss: 2.8911 - val_accuracy: 0.4514\n",
            "Epoch 38/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.7546 - val_loss: 2.9022 - val_accuracy: 0.4514\n",
            "Epoch 39/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.7552 - val_loss: 2.9089 - val_accuracy: 0.4514\n",
            "Epoch 40/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.7552 - val_loss: 2.9191 - val_accuracy: 0.4514\n"
          ]
        }
      ],
      "source": [
        "binary_model = tf.keras.Sequential([layers.Dense(82)])\n",
        "\n",
        "binary_model.compile(\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = binary_model.fit(\n",
        "    binary_train_ds, validation_data=binary_val_ds, epochs=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "SKrVsFe5phXa"
      },
      "outputs": [],
      "source": [
        "def create_model(vocab_size, num_labels):\n",
        "  model = tf.keras.Sequential([\n",
        "      layers.Embedding(vocab_size, 64, mask_zero=True),\n",
        "      layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
        "      layers.GlobalMaxPooling1D(),\n",
        "      layers.Dense(num_labels)\n",
        "  ])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6uDy8XQpiJQ",
        "outputId": "09375459-995d-416e-9222-0ee39c95ede1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "48/48 [==============================] - 8s 140ms/step - loss: 4.2677 - accuracy: 0.0604 - val_loss: 4.1203 - val_accuracy: 0.0551\n",
            "Epoch 2/40\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 3.8416 - accuracy: 0.1148 - val_loss: 3.9229 - val_accuracy: 0.1155\n",
            "Epoch 3/40\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 3.5696 - accuracy: 0.1962 - val_loss: 3.7928 - val_accuracy: 0.1522\n",
            "Epoch 4/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 3.2986 - accuracy: 0.2657 - val_loss: 3.6364 - val_accuracy: 0.1890\n",
            "Epoch 5/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 2.9786 - accuracy: 0.3747 - val_loss: 3.4604 - val_accuracy: 0.2415\n",
            "Epoch 6/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 2.6100 - accuracy: 0.4980 - val_loss: 3.2780 - val_accuracy: 0.3176\n",
            "Epoch 7/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 2.2146 - accuracy: 0.5997 - val_loss: 3.1037 - val_accuracy: 0.3701\n",
            "Epoch 8/40\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 1.8335 - accuracy: 0.6778 - val_loss: 2.9648 - val_accuracy: 0.3806\n",
            "Epoch 9/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 1.5083 - accuracy: 0.7093 - val_loss: 2.8777 - val_accuracy: 0.3885\n",
            "Epoch 10/40\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 1.2569 - accuracy: 0.7244 - val_loss: 2.8358 - val_accuracy: 0.3832\n",
            "Epoch 11/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 1.0727 - accuracy: 0.7336 - val_loss: 2.8231 - val_accuracy: 0.3858\n",
            "Epoch 12/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.9388 - accuracy: 0.7454 - val_loss: 2.8307 - val_accuracy: 0.3832\n",
            "Epoch 13/40\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.8434 - accuracy: 0.7493 - val_loss: 2.8521 - val_accuracy: 0.3806\n",
            "Epoch 14/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.7741 - accuracy: 0.7448 - val_loss: 2.8795 - val_accuracy: 0.3885\n",
            "Epoch 15/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.7225 - accuracy: 0.7461 - val_loss: 2.9112 - val_accuracy: 0.3858\n",
            "Epoch 16/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.6849 - accuracy: 0.7454 - val_loss: 2.9430 - val_accuracy: 0.3885\n",
            "Epoch 17/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.6568 - accuracy: 0.7454 - val_loss: 2.9729 - val_accuracy: 0.3911\n",
            "Epoch 18/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.6348 - accuracy: 0.7474 - val_loss: 2.9983 - val_accuracy: 0.3937\n",
            "Epoch 19/40\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.6186 - accuracy: 0.7421 - val_loss: 3.0229 - val_accuracy: 0.3937\n",
            "Epoch 20/40\n",
            "48/48 [==============================] - 0s 8ms/step - loss: 0.6059 - accuracy: 0.7448 - val_loss: 3.0452 - val_accuracy: 0.3911\n",
            "Epoch 21/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5958 - accuracy: 0.7428 - val_loss: 3.0638 - val_accuracy: 0.3885\n",
            "Epoch 22/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5868 - accuracy: 0.7434 - val_loss: 3.0818 - val_accuracy: 0.3885\n",
            "Epoch 23/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5800 - accuracy: 0.7434 - val_loss: 3.1023 - val_accuracy: 0.3858\n",
            "Epoch 24/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5738 - accuracy: 0.7448 - val_loss: 3.1176 - val_accuracy: 0.3858\n",
            "Epoch 25/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5689 - accuracy: 0.7467 - val_loss: 3.1327 - val_accuracy: 0.3832\n",
            "Epoch 26/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5648 - accuracy: 0.7434 - val_loss: 3.1471 - val_accuracy: 0.3832\n",
            "Epoch 27/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.7461 - val_loss: 3.1610 - val_accuracy: 0.3832\n",
            "Epoch 28/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5573 - accuracy: 0.7441 - val_loss: 3.1726 - val_accuracy: 0.3832\n",
            "Epoch 29/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7434 - val_loss: 3.1850 - val_accuracy: 0.3780\n",
            "Epoch 30/40\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.5516 - accuracy: 0.7428 - val_loss: 3.1953 - val_accuracy: 0.3780\n",
            "Epoch 31/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5492 - accuracy: 0.7434 - val_loss: 3.2060 - val_accuracy: 0.3780\n",
            "Epoch 32/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5474 - accuracy: 0.7428 - val_loss: 3.2144 - val_accuracy: 0.3780\n",
            "Epoch 33/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5455 - accuracy: 0.7467 - val_loss: 3.2243 - val_accuracy: 0.3753\n",
            "Epoch 34/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5436 - accuracy: 0.7454 - val_loss: 3.2336 - val_accuracy: 0.3753\n",
            "Epoch 35/40\n",
            "48/48 [==============================] - 0s 8ms/step - loss: 0.5422 - accuracy: 0.7441 - val_loss: 3.2426 - val_accuracy: 0.3753\n",
            "Epoch 36/40\n",
            "48/48 [==============================] - 0s 8ms/step - loss: 0.5410 - accuracy: 0.7461 - val_loss: 3.2512 - val_accuracy: 0.3753\n",
            "Epoch 37/40\n",
            "48/48 [==============================] - 0s 8ms/step - loss: 0.5392 - accuracy: 0.7461 - val_loss: 3.2603 - val_accuracy: 0.3780\n",
            "Epoch 38/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.5377 - accuracy: 0.7454 - val_loss: 3.2689 - val_accuracy: 0.3780\n",
            "Epoch 39/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.5361 - accuracy: 0.7474 - val_loss: 3.2762 - val_accuracy: 0.3780\n",
            "Epoch 40/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.5347 - accuracy: 0.7467 - val_loss: 3.2842 - val_accuracy: 0.3780\n"
          ]
        }
      ],
      "source": [
        "# `vocab_size` is `VOCAB_SIZE + 1` since `0` is used additionally for padding.\n",
        "int_model = create_model(vocab_size=VOCAB_SIZE + 1, num_labels=82)\n",
        "int_model.compile(\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "history = int_model.fit(int_train_ds, validation_data=int_val_ds, epochs=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFKwk9IAqvMZ",
        "outputId": "52126e69-a917-4d7d-8095-39ef4432f4ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear model on binary vectorized data:\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 82)                820082    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 820,082\n",
            "Trainable params: 820,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(\"Linear model on binary vectorized data:\")\n",
        "print(binary_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a24o-AXbqx-n",
        "outputId": "a1e2cca9-3c18-4224-b30f-a249cb5a6981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet model on int vectorized data:\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 64)          640064    \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, None, 64)          20544     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 82)                5330      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 665,938\n",
            "Trainable params: 665,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(\"ConvNet model on int vectorized data:\")\n",
        "print(int_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "X-Ld3hCqrXRe"
      },
      "outputs": [],
      "source": [
        "export_model = tf.keras.Sequential(\n",
        "    [binary_vectorize_layer, binary_model,\n",
        "     layers.Activation('sigmoid')])\n",
        "\n",
        "export_model.compile(\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "2gJNWruGrdAq"
      },
      "outputs": [],
      "source": [
        "def get_string_labels(predicted_scores_batch):\n",
        "  #predicted_int_labels = tf.math.argmax(predicted_scores_batch, axis=1)\n",
        "  #predicted_labels = tf.gather(raw_train_ds.class_names, predicted_int_labels)\n",
        "\n",
        "  predicted_values, predicted_indices = tf.math.top_k(predicted_scores_batch, k=10)\n",
        "  predicted_labels = tf.gather(raw_train_ds.class_names, predicted_indices)\n",
        "\n",
        "  return (predicted_values, predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF2gmyIGrCyQ",
        "outputId": "4766ff73-5fa5-4883-a2e3-d32965e0b7a4"
      },
      "outputs": [],
      "source": [
        "inputs = [x.lower() for x in tests]\n",
        "predicted_scores = export_model.predict(inputs)\n",
        "predicted_labels = get_string_labels(predicted_scores)\n",
        "with open(\"coursepreds.csv\", \"w\") as outputpredfile:\n",
        "  writer = csv.writer(outputpredfile, delimiter=',')\n",
        "  for i in range(0,len(inputs)):\n",
        "    print(\"Question: \", inputs[i])\n",
        "    print(\"Predicted label: \", predicted_labels[1][i].numpy())\n",
        "    print(\"Predicted weights: \", predicted_labels[0][i].numpy())\n",
        "    writer.writerow([names[i], str(predicted_labels[1][i].numpy()), str(predicted_labels[0][i].numpy())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"coursefullvectors.csv\", \"w\") as outputpredfile:\n",
        "  writer = csv.writer(outputpredfile, delimiter=',')\n",
        "  for i in range(0,len(inputs)):\n",
        "    print(\"Question: \", inputs[i])\n",
        "    writer.writerow([names[i], str(predicted_scores[i])])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
